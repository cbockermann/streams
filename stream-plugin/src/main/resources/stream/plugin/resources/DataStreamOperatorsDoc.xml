<?xml version="1.0" encoding="utf-8" standalone="no"?>
<operatorHelp lang="en_EN">
  <operator>
    <name>Data Stream Process</name>
    <synopsis/>
    <help>

&lt;p&gt;The &lt;em&gt;DataStreamProcess&lt;/em&gt; operator is a simple operator which will
iteratively read data items from a given data stream and apply
all its inner operators to each of the data items.&lt;/p&gt;

&lt;h2&gt;Conditioned Processing&lt;/h2&gt;

&lt;p&gt;An optional condition can be specified, which is a boolean expression
following the syntax of the &lt;a href="http://sfb876.cs.tu-dortmund.de/streams/stream-api/filter-language.html"&gt;stream-api filter language&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;A simple example is given below, which will result in processing only
the events, whose attribute &lt;code&gt;x1&lt;/code&gt; is larger than 5:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;   x1 @gt 5
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The same filter can also be specified at &lt;code&gt;x1 &amp;gt; 5&lt;/code&gt;.&lt;/p&gt;

&lt;h2&gt;Result Buffering&lt;/h2&gt;

&lt;p&gt;If the inner operators produce resulting data items, these can be
buffered as output and will be provided as a new stream to other
&lt;em&gt;DataStreamProcessor&lt;/em&gt;s connected to the output port.&lt;/p&gt;

&lt;p&gt;As buffering is currently performed in main memory, it is recommended
to provide a buffer size to not exceed any memory limits.&lt;/p&gt;
</help>
    <key>Data Stream Process</key>
  </operator>
  <operator>
    <name>Extract Example Set</name>
    <synopsis/>
    <help>

&lt;p&gt;This operator will collect a list of data items and create
an example-set from these. The specified &lt;code&gt;bufferSize&lt;/code&gt; parameter
allows for specifying the maximum number of data items that
will be collected before an example-set is emitted.&lt;/p&gt;
</help>
    <key>Extract Example Set</key>
  </operator>
  <operator>
    <name>Stream to ExampleSet</name>
    <synopsis/>
    <key>Stream to ExampleSet</key>
  </operator>
  <operator>
    <name>Delay</name>
    <synopsis/>
    <key>Delay</key>
  </operator>
  <operator>
    <name>Skip</name>
    <synopsis/>
    <key>Skip</key>
  </operator>
  <operator>
    <name>Prediction</name>
    <synopsis/>
    <help>&lt;p&gt;This processor references one or more learner elements using the &lt;code&gt;ref&lt;/code&gt; attribute. 
All the referenced elements need to provide a prediction model, i.e. need to
implement the ModelProvider interface.&lt;/p&gt;

&lt;p&gt;The processor will add the prediction of all referenced learners to the data item.
The prediction is prefixed with the &lt;code&gt;@prediction:&lt;/code&gt; string, followed by the name
of the model (usually the ID of the learner element).&lt;/p&gt;</help>
    <key>Prediction</key>
  </operator>
  <operator>
    <name>PredictionError</name>
    <synopsis/>
    <help>&lt;p&gt;This processor checks the processed data items for the existence of
a &lt;code&gt;@label&lt;/code&gt; and one or more &lt;code&gt;@prediction&lt;/code&gt; keys. It will compute the
loss of each of the &lt;code&gt;@prediction&lt;/code&gt; values against the &lt;code&gt;@label&lt;/code&gt; and add
an &lt;code&gt;@error&lt;/code&gt; value for each of these.&lt;/p&gt;

&lt;p&gt;As an example, assume that the data item contains a &lt;code&gt;@label&lt;/code&gt; key and
the predictions &lt;code&gt;@prediction:NaiveBayes&lt;/code&gt; and &lt;code&gt;@prediction:Perceptron&lt;/code&gt;.
Then the &lt;em&gt;PredictionError&lt;/em&gt; processor will add &lt;code&gt;@error:NaiveBayes&lt;/code&gt; and
&lt;code&gt;@error:Perceptron&lt;/code&gt;, which will contain the difference of the predicted
values against the &lt;code&gt;@label&lt;/code&gt; value.&lt;/p&gt;

&lt;p&gt;The default loss function is a "zero-one" loss.&lt;/p&gt;</help>
    <key>PredictionError</key>
  </operator>
  <operator>
    <name>Print Data</name>
    <synopsis/>
    <key>Print Data</key>
  </operator>
  <operator>
    <name>Statistics Logger</name>
    <synopsis/>
    <key>Statistics Logger</key>
  </operator>
  <operator>
    <name>CreateID</name>
    <synopsis/>
    <help>&lt;p&gt;This processor simply adds an incremental identifier to each processed
data item. By default, this identifier is stored as feature &lt;code&gt;@id&lt;/code&gt;, but
can be used with any other name as well.&lt;/p&gt;

&lt;p&gt;The following example creates a processor adding IDs with name &lt;code&gt;@uid&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt; &amp;lt;CreateID key="@uid" /&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;IDs are numbered starting from 0, but can also start at arbitrary
integer values:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt; &amp;lt;CreateID key="@uid" start="10" /&amp;gt;
&lt;/code&gt;&lt;/pre&gt;</help>
    <key>CreateID</key>
  </operator>
  <operator>
    <name>Array to ExampleSet</name>
    <synopsis/>
    <key>Array to ExampleSet</key>
  </operator>
  <operator>
    <name>ExampleSet to Array</name>
    <synopsis/>
    <key>ExampleSet to Array</key>
  </operator>
  <operator>
    <name>Merge Data Items</name>
    <synopsis/>
    <key>Merge Data Items</key>
  </operator>
  <operator>
    <name>JavaScript</name>
    <synopsis/>
    <help>&lt;p&gt;This processor can be used to execute simple JavaScript snippets
using the Java-6 ECMA scripting engine.&lt;/p&gt;

&lt;p&gt;The processor binds the data item as &lt;code&gt;data&lt;/code&gt; object to the script
context to allow for accessing the item. The following snippet
prints out the message "Test" and stores the string &lt;code&gt;test&lt;/code&gt; with
key &lt;code&gt;@tag&lt;/code&gt; in the data object:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;  println( "Test" );
  data.put( "@tag", "Test" );
&lt;/code&gt;&lt;/pre&gt;

&lt;h2&gt;External Scripts&lt;/h2&gt;

&lt;p&gt;The processor can also be used to run JavaScript snippets from
external files, by simply specifying the &lt;code&gt;file&lt;/code&gt; attribute:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;JavaScript file="/path/to/script.js" /&amp;gt;
&lt;/code&gt;&lt;/pre&gt;</help>
    <key>JavaScript</key>
  </operator>
  <operator>
    <name>MapKeys</name>
    <synopsis/>
    <help>&lt;p&gt;This processor provides a way to map keys (feature names) to other
values. This is sometimes required to match special processors that
rely on specific feature names:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;  &amp;lt;MapKeys from="labelAttribute" to="@label" /&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;A more complex setting can be used by specifying the map in a &lt;code&gt;key=value&lt;/code&gt;
file, e.g. stored as &lt;code&gt;my-map.txt&lt;/code&gt;. With such a file, the processor can
be specified as:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;  &amp;lt;MapKeys map="my-map.txt" /&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;where the &lt;code&gt;my-map.txt&lt;/code&gt; file may look like&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;  attr1=sepalLength
  attr2=sepalWidth
  ...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;which will map the keys according to the map. &lt;/p&gt;</help>
    <key>MapKeys</key>
  </operator>
  <operator>
    <name>RemoveAttributes</name>
    <synopsis/>
    <help>&lt;p&gt;This processors provides the possibility to remove a set of features
from each processed data item. The list can be specified by setting
the &lt;code&gt;keys&lt;/code&gt; parameter to the list of features to be removed:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;  &amp;lt;RemoveAttributes keys="attr1,attr2,attr3" /&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The key strings will be splitted at each comma and will be trimmed,
i.e. the list above will have the same effect as the following:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;  &amp;lt;RemoveAttributes keys="attr1, attr2 , attr3" /&amp;gt;
&lt;/code&gt;&lt;/pre&gt;</help>
    <key>RemoveAttributes</key>
  </operator>
  <operator>
    <name>TrimKeys</name>
    <synopsis/>
    <help>&lt;p&gt;This operator removes leading and trailing whitespaces from all
keys of a data item, i.e. the item&lt;/p&gt;

&lt;pre&gt;&lt;code&gt; x1  =1.0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;will be transformed to&lt;/p&gt;

&lt;pre&gt;&lt;code&gt; x1=1.0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;as the key "&lt;code&gt;x1&lt;/code&gt;" will be renamed to "&lt;code&gt;x1&lt;/code&gt;" (without the quotes).&lt;/p&gt;</help>
    <key>TrimKeys</key>
  </operator>
  <operator>
    <name>MapValueToID</name>
    <synopsis/>
    <help>&lt;p&gt;This processor provides a way to map values of a specific feature
to integer IDs, starting with 1 as first ID. The processor will
maintain a map of value-to-IDs and extend that map for new values.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;  &amp;lt;MapValueToID key="data" /&amp;gt;
&lt;/code&gt;&lt;/pre&gt;</help>
    <key>MapValueToID</key>
  </operator>
  <operator>
    <name>MapValues</name>
    <synopsis/>
    <help>&lt;p&gt;This processor provides a way to map values of a specific feature
onto other values. For example, mapping all labels &lt;code&gt;0.0&lt;/code&gt; to the
value &lt;code&gt;-1.0&lt;/code&gt; can be done using&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;  &amp;lt;MapValues key="@label" from="0.0" to="-1.0" /&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This is useful, e.g. when required to map labels or other categorical
data to different values.&lt;/p&gt;

&lt;p&gt;A more complex setting can be used by specifying the map in a &lt;code&gt;key=value&lt;/code&gt;
file, e.g. stored as &lt;code&gt;my-map.txt&lt;/code&gt;. With such a file, the processor can
be specified as:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;  &amp;lt;MapValues key="@label" map="my-map.txt" /&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;where the &lt;code&gt;my-map.txt&lt;/code&gt; file may look like&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;  false=-1.0
  true=1.0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;which will map the string values &lt;code&gt;true&lt;/code&gt; and &lt;code&gt;false&lt;/code&gt; according to the map. &lt;/p&gt;</help>
    <key>MapValues</key>
  </operator>
  <operator>
    <name>RemoveZeroes</name>
    <synopsis/>
    <help>&lt;p&gt;This processor will remove any values which equal 0 in the numerical
sense. This can be used to remove a large number of features to create
a sparse item:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;  &amp;lt;RemoveZeroes /&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Special attributes, such as &lt;code&gt;@label&lt;/code&gt; or similar are left untouched.&lt;/p&gt;</help>
    <key>RemoveZeroes</key>
  </operator>
  <operator>
    <name>SetValue</name>
    <synopsis/>
    <help>&lt;p&gt;This processors allows for setting a feature to a single, constant
value:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;  &amp;lt;SetValue key="attribute1" value="abc" /&amp;gt;
&lt;/code&gt;&lt;/pre&gt;</help>
    <key>SetValue</key>
  </operator>
  <operator>
    <name>Timestamp</name>
    <synopsis/>
    <key>Timestamp</key>
  </operator>
  <operator>
    <name>AccessLogStream</name>
    <synopsis/>
    <key>AccessLogStream</key>
  </operator>
  <operator>
    <name>ArffStream</name>
    <synopsis/>
    <key>ArffStream</key>
  </operator>
  <operator>
    <name>CSV Data Stream</name>
    <synopsis/>
    <key>CSV Data Stream</key>
  </operator>
  <operator>
    <name>CsvStream</name>
    <synopsis/>
    <help>&lt;p&gt;This data stream source reads simple comma separated values
from a file/url. Each line is split using a separator (regular
expression).&lt;/p&gt;

&lt;p&gt;Lines starting with a hash character (&lt;code&gt;#&lt;/code&gt;) are regarded to be
headers which define the names of the columns.&lt;/p&gt;

&lt;p&gt;The default split expression is &lt;code&gt;(;|,)&lt;/code&gt;, but this can changed
to whatever is required using the &lt;code&gt;separator&lt;/code&gt; parameter.&lt;/p&gt;</help>
    <key>CsvStream</key>
  </operator>
  <operator>
    <name>ExampleSet DataStream</name>
    <synopsis/>
    <help>

&lt;p&gt;This operator simply creates a &lt;em&gt;data stream&lt;/em&gt; handle from an existing
example set. The example set will most likely remain in main memory
and the resulting &lt;em&gt;data stream&lt;/em&gt; handle will provide a sequential access
to each of the examples.&lt;/p&gt;

&lt;p&gt;The operator is intended to work as adapter for existing datasets to be
processed stream-wise.&lt;/p&gt;
</help>
    <key>ExampleSet DataStream</key>
  </operator>
  <operator>
    <name>FACT Event Stream</name>
    <synopsis/>
    <help>

&lt;p&gt;This operator provides a &lt;em&gt;data stream handle&lt;/em&gt; that reads data
from FITS files as produced by the FACT telescope. Each data item
that can be retrieved from the stream resembles a single FACT
event, i.e. an observation by the telescope.&lt;/p&gt;

&lt;p&gt;The single data items consists of several features, such as the
&lt;code&gt;EventNum&lt;/code&gt;, the &lt;code&gt;TriggerType&lt;/code&gt; and also the &lt;code&gt;Data&lt;/code&gt;, which is a large
array of 432000 elements (1440 x 300).&lt;/p&gt;

&lt;h2&gt;DRS Calibration&lt;/h2&gt;

&lt;p&gt;The &lt;em&gt;FactEventReader&lt;/em&gt; operator also provides DRS calibration if a
DRS calibration data file has been specified. In that case, the
&lt;code&gt;Data&lt;/code&gt; feature is converted into a 432000 element array with calibrated
data values.&lt;/p&gt;

&lt;h2&gt;Event Keys&lt;/h2&gt;

&lt;p&gt;Despite the &lt;code&gt;EventNum&lt;/code&gt;, &lt;code&gt;TriggerType&lt;/code&gt; and &lt;code&gt;Data&lt;/code&gt; each event provides
additional attributes/keys as outlined in the following.&lt;/p&gt;

&lt;table&gt;

&lt;tr&gt;
  &lt;th&gt;Key&lt;/th&gt;
  &lt;th&gt;Description&lt;/th&gt;
&lt;/tr&gt;

&lt;tr&gt;
  &lt;td&gt;&lt;b&gt;@id&lt;/b&gt;&lt;/td&gt;
  &lt;td&gt;This attributes contains a special string that uniquely identified
      a single event by its recording date, run-number and event number.
      For example the id `2011/11/27/42/1` refers to the 1st event recorded
      in run 42 on the 27th of November 2011.
  &lt;/td&gt;
&lt;/tr&gt;

&lt;/table&gt;
</help>
    <key>FACT Event Stream</key>
  </operator>
  <operator>
    <name>JSONStream</name>
    <synopsis/>
    <help>&lt;p&gt;This data stream reads JSON objects from the source (file/url) and
returns the corresponding Data items.&lt;/p&gt;</help>
    <key>JSONStream</key>
  </operator>
  <operator>
    <name>LineStream</name>
    <synopsis/>
    <help>&lt;p&gt;This is a very simple stream that just reads from a URL line-by-line. The
content of the line is stored in the attribute determined by the
&lt;code&gt;key&lt;/code&gt; parameter. By default the key &lt;code&gt;LINE&lt;/code&gt; is used.&lt;/p&gt;

&lt;p&gt;It also supports the specification of a simple format string that can be used
to create a generic parser to populate additional fields of the data item
read from the stream.&lt;/p&gt;

&lt;p&gt;The parser format is:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;  %{IP} [%{DATE}] "%{URL}"
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This will create a parser that is able to read line in the format&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;  127.0.0.1 [2012/03/14 12:03:48 +0100] "http://example.com/index.html"
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The outcoming data item will have the attribute &lt;code&gt;IP&lt;/code&gt; set to
&lt;code&gt;127.0.0.1&lt;/code&gt; and the &lt;code&gt;DATE&lt;/code&gt; attribute set to
&lt;code&gt;2012/03/14 12:03:48 +0100&lt;/code&gt;. The &lt;code&gt;URL&lt;/code&gt; attribute will be set to
&lt;code&gt;http://example.com/index.html&lt;/code&gt;.
In addition, the &lt;code&gt;LINE&lt;/code&gt; attribute will contain the complete line string.&lt;/p&gt;</help>
    <key>LineStream</key>
  </operator>
  <operator>
    <name>LogDataStream</name>
    <synopsis/>
    <key>LogDataStream</key>
  </operator>
  <operator>
    <name>ModSecurityAuditStream</name>
    <synopsis/>
    <key>ModSecurityAuditStream</key>
  </operator>
  <operator>
    <name>SparseDataStream</name>
    <synopsis/>
    <key>SparseDataStream</key>
  </operator>
  <operator>
    <name>SvmLightDataStream</name>
    <synopsis/>
    <key>SvmLightDataStream</key>
  </operator>
  <operator>
    <name>SyslogDataStream</name>
    <synopsis/>
    <key>SyslogDataStream</key>
  </operator>
</operatorHelp>
