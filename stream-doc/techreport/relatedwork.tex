%%
%% In this section:
%%
%%   - explain stream setting, problems and objectives/aims
%%   - theoretical frameworks?
%%   - stream processes, continuous systems
%%   - Frameworks
%%        - batch processing: RM, Weka
%%        - mini-batches + parallelization:  MapReduce,Hadoop,Radoop
%%        - stream processing: moa,s4.io,storm,Streams-Plugin
%%
%%   - ggf. Übersichtstabelle mit den Ansätzen und Einordnen des Streams Plugin?
%%
%% (  - refine the basic problems and task/settings we want to address )
%% (  - give an overview of existing frameworks/solutions )
%% (  - outline the differences of the streams library to this solutions )
%%
\section{\label{sec:relatedWork}Problem and Related Work}

%
%. The {\em data items} $s_i$ are tuples of
%$M^p$ with $p \ge 1$ where $M^p = M_1 \times \ldots \times M_p$ for
%any sets $M_j$. 
%
%The $M_j$ can be any discrete sets of a fixed domain as well as $M_k
%\subseteq \mathbb{R}$. The index $i$ may reflect some time unit or an
%(monotonically increasing) time like dimension, constituting the
%sequence of tuples. For $p=1$ and $M_1 = \mathbb{R}$ this models a
%single value series with index $i$.
%The data processing model of streaming approaches share common
%criteria.
% induced by the continuous nature of the problem. 

Several algorithms to the task mentioned above with respect to these
requirements have been proposed. Regarding the counting of elements
and sets of items, a variety of different approximate count algorithms
based on sketches of the data have been developed in
\cite{Charikar02findingfrequent,goethals2007,Cheng06maintainingfrequent}.
For statistical model, estimators for quantiles have been presented in
\cite{Greenwald/Khanna/2001a,Arasu/Manku/2004a}.



\bigskip

Whereas a wide range of different methods have been provided for
various streaming tasks, this work aims at providing an abstract
framework to integrate these different approaches into a flexible
environment to build a streaming analysis based upon the existing
algorithms.

%%The examples outlined above show typical use cases of high-volume
%%continues data that is either stored in large batches (e.g. 5-minute
%%recording intervals of the FACT telescope) or continuously produced
%%by non-terminating processes.
%%
%%The results is a sequence of 150 images (slices), each containing 1440
%%pixels.  As the shower is not clearly identifiable, a {\em region of
%%  interest} of about 300 slices is recorded, which results in 432000
%%raw data values for a single shower (event). 
%%
%%Currently showers are recorded at a rate of 60 Hz, resulting in 60 of
%%such events being stored each second. With additional information for
%%each shower, a 5 minute recording interval quickly produces several
%%gigabytes of raw data that is to be preprocessed and analyzed.
%%
%With nowadays data volume, the traditional batch processing model
%quickly reaches the resource limitations of single workstations. Even
%applying a previously created prediction model to a large set of
%examples can quickly become impossible if the example set itself does
%not fit into main memory. The only cumbersome solution often is to
%split the data into several files and process each file separately.
%We will refer to this setting as the {\em partial batch processing}.
%This processing typically requires the results of the processed
%batches to be combined, for example by computing an average.
%
%In some cases, the data is not even static, but continuosly produced
%by some data generating process. In the simplest case we might be able
%to write batches of that data into files and fall back to the mini
%batch processing approach. Therefore in this work we are more
%interested in continuously processing that data and provide models or
%services in an {\em anytime} manner, that is the current models or
%statistics can be queried at any time. We will refer to this setting
%as the ({\em continuous}) {\em stream processing}.  When dealing with
%a finite source of data we can consider the {\em stream processing} as
%a special case of {\em partial batch processing} with a batch size of 1.
%
%The data processing model of streaming approaches share common
%criteria.
% induced by the continuous nature of the problem. 
%The framing to operate on streaming data is generally given by the
%following constraints/requirements:
%\begin{itemize}
%  \item[\textsf{C1}] continuously processing {\em single items} or {\em small batches} of data,
%  \item[\textsf{C2}] using only a {\em single pass} over the data,
%  \item[\textsf{C3}] using {\em limited resources} (memory, time),
%  \item[\textsf{C4}] provide {\em anytime services} (models, statistics).
%\end{itemize}
%This contrasts to the RapidMiner batch-processing model, where a set
%of examples is usually processed in its entirety and during a single
%execution of a RapidMiner process.


\subsection*{Existing Frameworks}
%Various frameworks exist that support either of these two processing
%modes.
Parallel batch processing is addressing the setting of fixed data and
is of limited use if data is non-stationary but continuously produced,
for example in monitoring applications (server log files, sensor
networks).  A framework that provides online analysis is the MOA
library \cite{moa}, which is a Java library closely related to the
WEKA data mining framework \cite{weka}. MOA provides a collection of
online learning algorithms with a focus on evaluation and
benchmarking.

Aiming at processing high-volume data streams two environments have
been proposed by Yahoo! and Twitter. Yahoo!'s {\em S4} \cite{s4io}
as well as Twitter's {\em Storm} \cite{storm} framework do provide
online processing and storage on large cluster infrastructures, but
these do not include any online learning.

In contrast to these frameworks, the \streams library focuses on
defining a simple abstraction layer that allows for the definition of
stream processes which can be mapped to different backend
infrastructures (such as {\em S4} or {\em Storm}).

%Providing an execution environment for data stream processing is given
%in s4.io \cite{s4io} and {\em storm} \cite{storm}. These libraries
%... \todo{More details about s4io/storm}.

